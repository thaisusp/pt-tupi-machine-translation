{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **EP2 MAC0508 - Processamento de Linguagem**\n"
      ],
      "metadata": {
        "id": "8hotBKmyGHO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modernização da face em Português do Corpus Paralelo através do GPT 4o mini"
      ],
      "metadata": {
        "id": "5Q9HYjD5hqTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import csv\n",
        "import difflib\n",
        "from typing import List, Dict, Any, Tuple\n",
        "from openai import OpenAI\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "\n",
        "# =========================\n",
        "# CONFIGURAÇÕES\n",
        "# =========================\n",
        "INPUT_CSV = \"/content/drive/MyDrive/0_tupi/tupiantigo_portugues_limpo.csv\"\n",
        "OUTPUT_CSV = \"/content/drive/MyDrive/0_tupi/tupiantigo_portugues_modernizado.csv\"\n",
        "\n",
        "COLUNA_TEXTO = \"source_text\"\n",
        "COLUNA_ID = \"id\"\n",
        "COLUNA_SAIDA = \"modern_source_text\"\n",
        "\n",
        "BATCH_SIZE = 30\n",
        "MODEL = \"gpt-4o-mini\"\n",
        "TEMPERATURA = 0.0\n",
        "\n",
        "LIMIAR_SIMILARIDADE_FALLBACK = 0.3\n",
        "\n",
        "# Relatório\n",
        "SIMILARIDADE_MUITO_ALTERADA = 0.80\n",
        "MAX_EXEMPLOS_IGUAIS = 15\n",
        "MAX_EXEMPLOS_MUITO_ALTERADAS = 15\n",
        "\n",
        "# Rate limit / robustez\n",
        "SLEEP_ENTRE_BATCHES = 0.25\n",
        "MAX_RETRIES = 6\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GZDosm-htqI",
        "outputId": "77adc7c3-6941-42a9-9b04-2f4a18d7f09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# PROMPTS\n",
        "# =========================\n",
        "PROMPT_SISTEMA = \"\"\"\n",
        "Você é um assistente especializado em normalizar português antigo para português brasileiro contemporâneo.\n",
        "\n",
        "Instruções obrigatórias:\n",
        "- Reescreva cada texto preservando totalmente o sentido original.\n",
        "- Não resuma, não interprete, não invente informações novas, nem substitua trechos por expressões vagas (“de verdade”, “tipo assim”, etc.).\n",
        "- Não omita partes do texto: todo conteúdo informativo do original deve aparecer na versão modernizada.\n",
        "- Não altere nomes próprios, datas, referências históricas ou fatos.\n",
        "- Não altere capitalização (maiúsculas/minúsculas) do texto original.\n",
        "- Não introduza novas frases, exemplos ou explicações.\n",
        "- Não altere o tempo verbal dos verbos.\n",
        "- Reescreva com fluência natural em português brasileiro contemporâneo, podendo ajustar a ordem das palavras e pontuação quando necessário, sem acrescentar conteúdo.\n",
        "- Normalize apenas construções arcaicas, ortografia e conectores.\n",
        "- Padronize tratamento do interlocutor para PT-BR contemporâneo:\n",
        "  \"a ti\"→\"a você\"; formas de \"vós\" (ex.: \"fazei\", \"dizei\") → \"vocês\" + imperativo correspondente (\"façam\", \"digam\").\n",
        "  Em ambiguidade de número, prefira \"vocês\" (plural).\n",
        "- Em caso de dúvida sobre o significado de uma expressão arcaica, mantenha a expressão (corrigindo só ortografia/pontuação), em vez de substituir por paráfrase livre.\n",
        "- Não modifique o campo \"id\" de cada item.\n",
        "- Retorne apenas um array JSON válido, sem texto adicional, sem comentários e sem blocos de código.\n",
        "\n",
        "Formato de saída obrigatório:\n",
        "[\n",
        "  {{\"id\": <mesmo id fornecido>, \"modernizado\": \"<texto modernizado em português brasileiro contemporâneo>\"}},\n",
        "  ...\n",
        "]\n",
        "\n",
        "Requisitos estritos:\n",
        "- A saída deve ser SOMENTE JSON.\n",
        "- Não inclua delimitadores como ```json.\n",
        "- Não mude a ordem dos itens.\n",
        "- Garanta que todo texto modernizado esteja corretamente escapado em JSON.\n",
        "\"\"\".strip()\n",
        "\n",
        "PROMPT_USUARIO_TEMPLATE = \"\"\"\n",
        "Aqui está um lote de textos. Para cada item fornecido, retorne exatamente um objeto JSON no formato:\n",
        "{{\"id\": <id>, \"modernizado\": \"<texto modernizado>\"}}\n",
        "\n",
        "Regras:\n",
        "- Use o mesmo \"id\" recebido.\n",
        "- O campo \"modernizado\" deve conter apenas a versão modernizada do texto correspondente.\n",
        "- Não repita o texto original no JSON.\n",
        "- Não adicione campos extras.\n",
        "- Não adicione explicações.\n",
        "\n",
        "Lote:\n",
        "{}\n",
        "\"\"\".strip()"
      ],
      "metadata": {
        "id": "70YLuLhjiL4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# FUNÇÕES UTILITÁRIAS\n",
        "# =========================\n",
        "def criar_client() -> OpenAI:\n",
        "    api_key = \"API_KEY\" #aqui entra a chave\n",
        "\n",
        "    return OpenAI(api_key=api_key)\n",
        "\n",
        "\n",
        "\n",
        "_JSON_FENCE_RE = re.compile(r\"^\\s*```(?:json)?\\s*|\\s*```\\s*$\", re.IGNORECASE)\n",
        "def extrair_json_puro(conteudo: str) -> str:\n",
        "    s = (conteudo or \"\").strip()\n",
        "    s = _JSON_FENCE_RE.sub(\"\", s).strip()\n",
        "\n",
        "    start = s.find(\"[\")\n",
        "    end = s.rfind(\"]\")\n",
        "    if start != -1 and end != -1 and end > start:\n",
        "        s = s[start:end + 1].strip()\n",
        "\n",
        "    return s\n",
        "\n",
        "\n",
        "def similaridade(a: str, b: str) -> float:\n",
        "    return difflib.SequenceMatcher(None, a, b).ratio()\n",
        "\n",
        "\n",
        "def garantir_colunas(linhas: List[Dict[str, Any]]) -> Tuple[List[str], List[Dict[str, Any]]]:\n",
        "    if not linhas:\n",
        "        raise RuntimeError(\"CSV vazio.\")\n",
        "    if COLUNA_TEXTO not in linhas[0]:\n",
        "        raise RuntimeError(f\"Coluna '{COLUNA_TEXTO}' não existe no CSV.\")\n",
        "\n",
        "\n",
        "    if COLUNA_ID not in linhas[0]:\n",
        "        for i, row in enumerate(linhas):\n",
        "            row[COLUNA_ID] = str(i)\n",
        "        print(f\"[Info] Coluna '{COLUNA_ID}' não existia; criei IDs sequenciais.\")\n",
        "    else:\n",
        "        for row in linhas:\n",
        "            row[COLUNA_ID] = str(row.get(COLUNA_ID, \"\")).strip()\n",
        "\n",
        "\n",
        "    for row in linhas:\n",
        "        if COLUNA_SAIDA not in row:\n",
        "            row[COLUNA_SAIDA] = \"\"\n",
        "\n",
        "    fieldnames = list(linhas[0].keys())\n",
        "    if COLUNA_SAIDA not in fieldnames:\n",
        "        fieldnames.append(COLUNA_SAIDA)\n",
        "\n",
        "    return fieldnames, linhas\n",
        "\n",
        "\n",
        "def carregar_csv(path: str) -> List[Dict[str, Any]]:\n",
        "    with open(path, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
        "        return list(csv.DictReader(f))\n",
        "\n",
        "\n",
        "def salvar_csv(path: str, linhas: List[Dict[str, Any]], fieldnames: List[str]) -> None:\n",
        "    with open(path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "        writer.writerows(linhas)\n",
        "\n"
      ],
      "metadata": {
        "id": "EzvLjyLFiEpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# API\n",
        "# =========================\n",
        "def modernizar_batch(client: OpenAI, batch: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
        "    lote_json = json.dumps(batch, ensure_ascii=False)\n",
        "    prompt_usuario = PROMPT_USUARIO_TEMPLATE.format(lote_json)\n",
        "\n",
        "    last_err = None\n",
        "    for attempt in range(MAX_RETRIES):\n",
        "        try:\n",
        "            resp = client.chat.completions.create(\n",
        "                model=MODEL,\n",
        "                temperature=TEMPERATURA,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": PROMPT_SISTEMA},\n",
        "                    {\"role\": \"user\", \"content\": prompt_usuario},\n",
        "                ],\n",
        "            )\n",
        "            conteudo = (resp.choices[0].message.content or \"\").strip()\n",
        "            json_puro = extrair_json_puro(conteudo)\n",
        "            data = json.loads(json_puro)\n",
        "\n",
        "            if not isinstance(data, list):\n",
        "                raise ValueError(\"JSON retornado não é uma lista.\")\n",
        "\n",
        "            for item in data:\n",
        "                if not isinstance(item, dict) or \"id\" not in item or \"modernizado\" not in item:\n",
        "                    raise ValueError(f\"Item inválido no JSON: {item}\")\n",
        "\n",
        "            return data\n",
        "\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            delay = min(2 ** attempt, 20) + (0.05 * attempt)\n",
        "            print(f\"[Aviso] Erro no batch (tentativa {attempt+1}/{MAX_RETRIES}): {e}\")\n",
        "            print(f\"[Aviso] Aguardando {delay:.2f}s e tentando novamente...\")\n",
        "            time.sleep(delay)\n",
        "\n",
        "    raise RuntimeError(f\"Falha após {MAX_RETRIES} tentativas. Último erro: {last_err}\")\n"
      ],
      "metadata": {
        "id": "K6EDBg6LiAly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# BATCHING / APLICAÇÃO\n",
        "# =========================\n",
        "def construir_batch(linhas: List[Dict[str, Any]], start: int, end: int) -> Tuple[List[Dict[str, Any]], Dict[str, int]]:\n",
        "    fatia = linhas[start:end]\n",
        "    batch = []\n",
        "    index_por_id = {}\n",
        "\n",
        "    for offset, row in enumerate(fatia):\n",
        "        abs_idx = start + offset\n",
        "        texto = str(row.get(COLUNA_TEXTO, \"\") or \"\")\n",
        "        rid = str(row.get(COLUNA_ID, \"\")).strip()\n",
        "\n",
        "        if rid == \"\":\n",
        "            rid = str(abs_idx)\n",
        "            row[COLUNA_ID] = rid\n",
        "\n",
        "        if texto.strip() == \"\":\n",
        "            linhas[abs_idx][COLUNA_SAIDA] = \"\"\n",
        "            continue\n",
        "\n",
        "        batch.append({\"id\": rid, \"texto\": texto})\n",
        "        index_por_id[rid] = abs_idx\n",
        "\n",
        "    return batch, index_por_id\n",
        "\n",
        "\n",
        "def aplicar_resultados(\n",
        "    linhas: List[Dict[str, Any]],\n",
        "    resultados: List[Dict[str, Any]],\n",
        "    index_por_id: Dict[str, int],\n",
        "    iguais: List[Tuple[str, str]],\n",
        "    muito_alteradas: List[Tuple[str, str, str, float]],\n",
        ") -> None:\n",
        "    for item in resultados:\n",
        "        rid = str(item[\"id\"]).strip()\n",
        "        modern = str(item[\"modernizado\"])\n",
        "\n",
        "        if rid not in index_por_id:\n",
        "            continue\n",
        "\n",
        "        abs_idx = index_por_id[rid]\n",
        "        orig = str(linhas[abs_idx].get(COLUNA_TEXTO, \"\") or \"\")\n",
        "\n",
        "        o = orig.strip()\n",
        "        m = modern.strip()\n",
        "\n",
        "        s = similaridade(o, m) if (o and m) else 1.0\n",
        "\n",
        "        #Limiar de Fallback\n",
        "        if s < 0.30:\n",
        "            # grava o original no CSV\n",
        "            linhas[abs_idx][COLUNA_SAIDA] = orig\n",
        "            continue\n",
        "        else:\n",
        "            # grava a versão modernizada\n",
        "            linhas[abs_idx][COLUNA_SAIDA] = modern\n",
        "\n",
        "        # Relatório\n",
        "        if o == m:\n",
        "            if len(iguais) < MAX_EXEMPLOS_IGUAIS:\n",
        "                iguais.append((rid, o))\n",
        "        else:\n",
        "            if s < SIMILARIDADE_MUITO_ALTERADA and len(muito_alteradas) < MAX_EXEMPLOS_MUITO_ALTERADAS:\n",
        "                muito_alteradas.append((rid, o, m, s))\n",
        "\n",
        "\n",
        "def imprimir_relatorio(n: int, iguais, muito_alteradas, output_path: str) -> None:\n",
        "    print(\"\\n================ RELATÓRIO ================\\n\")\n",
        "    print(f\"Arquivo de saída: {output_path}\")\n",
        "    print(f\"Linhas totais: {n}\")\n",
        "\n",
        "    print(f\"\\nExemplos 'iguais' (até {MAX_EXEMPLOS_IGUAIS}): {len(iguais)}\")\n",
        "    for rid, o in iguais:\n",
        "        print(f\"- ID {rid}: {o}\")\n",
        "\n",
        "    print(\n",
        "        f\"\\nExemplos 'muito alteradas' (similaridade < {SIMILARIDADE_MUITO_ALTERADA}, \"\n",
        "        f\"até {MAX_EXEMPLOS_MUITO_ALTERADAS}): {len(muito_alteradas)}\"\n",
        "    )\n",
        "    for rid, o, m, s in muito_alteradas:\n",
        "        print(f\"\\n- ID {rid} | similaridade={s:.3f}\")\n",
        "        print(f\"  Original:    {o}\")\n",
        "        print(f\"  Modernizado: {m}\")\n",
        "\n",
        "    print(\"\\nProcesso concluído.\")"
      ],
      "metadata": {
        "id": "iDxeEddwsgX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# PIPELINES\n",
        "# =========================\n",
        "\n",
        "#Função para modernizar todo o corpus\n",
        "def processar_csv() -> None:\n",
        "    client = criar_client()\n",
        "\n",
        "    linhas = carregar_csv(INPUT_CSV)\n",
        "    fieldnames, linhas = garantir_colunas(linhas)\n",
        "\n",
        "    n = len(linhas)\n",
        "    total_batches = (n + BATCH_SIZE - 1) // BATCH_SIZE\n",
        "\n",
        "    iguais: List[Tuple[str, str]] = []\n",
        "    muito_alteradas: List[Tuple[str, str, str, float]] = []\n",
        "\n",
        "    for b in range(total_batches):\n",
        "        start = b * BATCH_SIZE\n",
        "        end = min(start + BATCH_SIZE, n)\n",
        "\n",
        "        batch, index_por_id = construir_batch(linhas, start, end)\n",
        "\n",
        "        if not batch:\n",
        "            print(f\"[Batch {b+1}/{total_batches}] vazio (só textos vazios). Pulando.\")\n",
        "            continue\n",
        "\n",
        "        print(f\"[Batch {b+1}/{total_batches}] Processando {len(batch)} itens...\")\n",
        "        resultados = modernizar_batch(client, batch)\n",
        "\n",
        "        aplicar_resultados(linhas, resultados, index_por_id, iguais, muito_alteradas)\n",
        "\n",
        "        salvar_csv(OUTPUT_CSV, linhas, fieldnames)  # incremental\n",
        "        time.sleep(SLEEP_ENTRE_BATCHES)\n",
        "\n",
        "    imprimir_relatorio(n, iguais, muito_alteradas, OUTPUT_CSV)\n",
        "\n",
        "\n",
        "#Função que moderniza uma amostra das N primeiras sentenças (utilizado no ajuste do prompt)\n",
        "def processar_csv_amostra(sample_size: int = 10) -> None:\n",
        "    client = criar_client()\n",
        "\n",
        "    linhas = carregar_csv(INPUT_CSV)\n",
        "    _, linhas = garantir_colunas(linhas)\n",
        "\n",
        "    batch = []\n",
        "    for row in linhas:\n",
        "        if len(batch) >= sample_size:\n",
        "            break\n",
        "        texto = str(row.get(COLUNA_TEXTO, \"\") or \"\")\n",
        "        if texto.strip():\n",
        "            batch.append({\"id\": str(row[COLUNA_ID]), \"texto\": texto})\n",
        "\n",
        "    if not batch:\n",
        "        print(\"Nada para processar (todos vazios).\")\n",
        "        return\n",
        "\n",
        "    resultados = modernizar_batch(client, batch)\n",
        "    mapa = {str(x[\"id\"]): str(x[\"modernizado\"]) for x in resultados}\n",
        "\n",
        "    print(\"\\n===== AMOSTRA =====\\n\")\n",
        "    for item in batch:\n",
        "        rid = str(item[\"id\"])\n",
        "        orig = item[\"texto\"].strip()\n",
        "        modern = mapa.get(rid, \"\").strip()\n",
        "\n",
        "\n",
        "        # só printa as frases alteradas para análise das alterações\n",
        "        if not (orig == modern):\n",
        "            print(f\"ID {rid}\")\n",
        "            print(f\"Original:    {orig}\")\n",
        "            print(f\"Modernizado: {modern}\")\n",
        "            s = similaridade(orig, modern)\n",
        "            print(f\"Status: similaridade={s:.3f}\\n\")"
      ],
      "metadata": {
        "id": "hUEmGAIbh3TB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Para rodar o processamento completo:\n",
        "processar_csv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2T6O89HXuaN",
        "outputId": "ef4c9581-0b64-4046-c97a-ce32fe9128da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Coluna 'id' não existia; criei IDs sequenciais.\n",
            "[Batch 1/232] Processando 30 itens...\n",
            "[Batch 2/232] Processando 30 itens...\n",
            "[Batch 3/232] Processando 30 itens...\n",
            "[Batch 4/232] Processando 30 itens...\n",
            "[Batch 5/232] Processando 30 itens...\n",
            "[Batch 6/232] Processando 30 itens...\n",
            "[Batch 7/232] Processando 30 itens...\n",
            "[Batch 8/232] Processando 30 itens...\n",
            "[Batch 9/232] Processando 30 itens...\n",
            "[Batch 10/232] Processando 30 itens...\n",
            "[Batch 11/232] Processando 30 itens...\n",
            "[Batch 12/232] Processando 30 itens...\n",
            "[Batch 13/232] Processando 30 itens...\n",
            "[Batch 14/232] Processando 30 itens...\n",
            "[Batch 15/232] Processando 30 itens...\n",
            "[Batch 16/232] Processando 30 itens...\n",
            "[Batch 17/232] Processando 30 itens...\n",
            "[Batch 18/232] Processando 30 itens...\n",
            "[Batch 19/232] Processando 30 itens...\n",
            "[Batch 20/232] Processando 30 itens...\n",
            "[Batch 21/232] Processando 30 itens...\n",
            "[Batch 22/232] Processando 30 itens...\n",
            "[Batch 23/232] Processando 30 itens...\n",
            "[Batch 24/232] Processando 30 itens...\n",
            "[Batch 25/232] Processando 30 itens...\n",
            "[Batch 26/232] Processando 30 itens...\n",
            "[Batch 27/232] Processando 30 itens...\n",
            "[Batch 28/232] Processando 30 itens...\n",
            "[Batch 29/232] Processando 30 itens...\n",
            "[Batch 30/232] Processando 30 itens...\n",
            "[Batch 31/232] Processando 30 itens...\n",
            "[Batch 32/232] Processando 30 itens...\n",
            "[Batch 33/232] Processando 30 itens...\n",
            "[Batch 34/232] Processando 30 itens...\n",
            "[Batch 35/232] Processando 30 itens...\n",
            "[Batch 36/232] Processando 30 itens...\n",
            "[Batch 37/232] Processando 30 itens...\n",
            "[Batch 38/232] Processando 30 itens...\n",
            "[Batch 39/232] Processando 30 itens...\n",
            "[Batch 40/232] Processando 30 itens...\n",
            "[Batch 41/232] Processando 30 itens...\n",
            "[Batch 42/232] Processando 30 itens...\n",
            "[Batch 43/232] Processando 30 itens...\n",
            "[Batch 44/232] Processando 30 itens...\n",
            "[Batch 45/232] Processando 30 itens...\n",
            "[Batch 46/232] Processando 30 itens...\n",
            "[Batch 47/232] Processando 30 itens...\n",
            "[Batch 48/232] Processando 30 itens...\n",
            "[Batch 49/232] Processando 30 itens...\n",
            "[Batch 50/232] Processando 30 itens...\n",
            "[Batch 51/232] Processando 30 itens...\n",
            "[Batch 52/232] Processando 30 itens...\n",
            "[Batch 53/232] Processando 30 itens...\n",
            "[Batch 54/232] Processando 30 itens...\n",
            "[Batch 55/232] Processando 30 itens...\n",
            "[Batch 56/232] Processando 30 itens...\n",
            "[Batch 57/232] Processando 30 itens...\n",
            "[Batch 58/232] Processando 30 itens...\n",
            "[Batch 59/232] Processando 30 itens...\n",
            "[Batch 60/232] Processando 30 itens...\n",
            "[Batch 61/232] Processando 30 itens...\n",
            "[Batch 62/232] Processando 30 itens...\n",
            "[Batch 63/232] Processando 30 itens...\n",
            "[Batch 64/232] Processando 30 itens...\n",
            "[Batch 65/232] Processando 30 itens...\n",
            "[Batch 66/232] Processando 30 itens...\n",
            "[Batch 67/232] Processando 30 itens...\n",
            "[Batch 68/232] Processando 30 itens...\n",
            "[Batch 69/232] Processando 30 itens...\n",
            "[Batch 70/232] Processando 30 itens...\n",
            "[Batch 71/232] Processando 30 itens...\n",
            "[Batch 72/232] Processando 30 itens...\n",
            "[Batch 73/232] Processando 30 itens...\n",
            "[Batch 74/232] Processando 30 itens...\n",
            "[Batch 75/232] Processando 30 itens...\n",
            "[Batch 76/232] Processando 30 itens...\n",
            "[Batch 77/232] Processando 30 itens...\n",
            "[Batch 78/232] Processando 30 itens...\n",
            "[Batch 79/232] Processando 30 itens...\n",
            "[Batch 80/232] Processando 30 itens...\n",
            "[Batch 81/232] Processando 30 itens...\n",
            "[Batch 82/232] Processando 30 itens...\n",
            "[Batch 83/232] Processando 30 itens...\n",
            "[Batch 84/232] Processando 30 itens...\n",
            "[Batch 85/232] Processando 30 itens...\n",
            "[Batch 86/232] Processando 30 itens...\n",
            "[Batch 87/232] Processando 30 itens...\n",
            "[Batch 88/232] Processando 30 itens...\n",
            "[Batch 89/232] Processando 30 itens...\n",
            "[Batch 90/232] Processando 30 itens...\n",
            "[Batch 91/232] Processando 30 itens...\n",
            "[Batch 92/232] Processando 30 itens...\n",
            "[Batch 93/232] Processando 30 itens...\n",
            "[Batch 94/232] Processando 30 itens...\n",
            "[Batch 95/232] Processando 30 itens...\n",
            "[Batch 96/232] Processando 30 itens...\n",
            "[Batch 97/232] Processando 30 itens...\n",
            "[Batch 98/232] Processando 30 itens...\n",
            "[Batch 99/232] Processando 30 itens...\n",
            "[Batch 100/232] Processando 30 itens...\n",
            "[Batch 101/232] Processando 30 itens...\n",
            "[Batch 102/232] Processando 30 itens...\n",
            "[Batch 103/232] Processando 30 itens...\n",
            "[Batch 104/232] Processando 30 itens...\n",
            "[Batch 105/232] Processando 30 itens...\n",
            "[Batch 106/232] Processando 30 itens...\n",
            "[Batch 107/232] Processando 30 itens...\n",
            "[Batch 108/232] Processando 30 itens...\n",
            "[Batch 109/232] Processando 30 itens...\n",
            "[Batch 110/232] Processando 30 itens...\n",
            "[Batch 111/232] Processando 30 itens...\n",
            "[Batch 112/232] Processando 30 itens...\n",
            "[Batch 113/232] Processando 30 itens...\n",
            "[Batch 114/232] Processando 30 itens...\n",
            "[Batch 115/232] Processando 30 itens...\n",
            "[Batch 116/232] Processando 30 itens...\n",
            "[Batch 117/232] Processando 30 itens...\n",
            "[Batch 118/232] Processando 30 itens...\n",
            "[Batch 119/232] Processando 30 itens...\n",
            "[Batch 120/232] Processando 30 itens...\n",
            "[Batch 121/232] Processando 30 itens...\n",
            "[Batch 122/232] Processando 30 itens...\n",
            "[Batch 123/232] Processando 30 itens...\n",
            "[Batch 124/232] Processando 30 itens...\n",
            "[Batch 125/232] Processando 30 itens...\n",
            "[Batch 126/232] Processando 30 itens...\n",
            "[Batch 127/232] Processando 30 itens...\n",
            "[Batch 128/232] Processando 30 itens...\n",
            "[Batch 129/232] Processando 30 itens...\n",
            "[Batch 130/232] Processando 30 itens...\n",
            "[Batch 131/232] Processando 30 itens...\n",
            "[Batch 132/232] Processando 30 itens...\n",
            "[Batch 133/232] Processando 30 itens...\n",
            "[Batch 134/232] Processando 30 itens...\n",
            "[Batch 135/232] Processando 30 itens...\n",
            "[Batch 136/232] Processando 30 itens...\n",
            "[Batch 137/232] Processando 30 itens...\n",
            "[Batch 138/232] Processando 30 itens...\n",
            "[Batch 139/232] Processando 30 itens...\n",
            "[Batch 140/232] Processando 30 itens...\n",
            "[Batch 141/232] Processando 30 itens...\n",
            "[Batch 142/232] Processando 30 itens...\n",
            "[Batch 143/232] Processando 30 itens...\n",
            "[Batch 144/232] Processando 30 itens...\n",
            "[Batch 145/232] Processando 30 itens...\n",
            "[Batch 146/232] Processando 30 itens...\n",
            "[Batch 147/232] Processando 30 itens...\n",
            "[Batch 148/232] Processando 30 itens...\n",
            "[Batch 149/232] Processando 30 itens...\n",
            "[Batch 150/232] Processando 30 itens...\n",
            "[Batch 151/232] Processando 30 itens...\n",
            "[Batch 152/232] Processando 30 itens...\n",
            "[Batch 153/232] Processando 30 itens...\n",
            "[Batch 154/232] Processando 30 itens...\n",
            "[Batch 155/232] Processando 30 itens...\n",
            "[Batch 156/232] Processando 30 itens...\n",
            "[Batch 157/232] Processando 30 itens...\n",
            "[Batch 158/232] Processando 30 itens...\n",
            "[Batch 159/232] Processando 30 itens...\n",
            "[Batch 160/232] Processando 30 itens...\n",
            "[Batch 161/232] Processando 30 itens...\n",
            "[Batch 162/232] Processando 30 itens...\n",
            "[Batch 163/232] Processando 30 itens...\n",
            "[Batch 164/232] Processando 30 itens...\n",
            "[Batch 165/232] Processando 30 itens...\n",
            "[Batch 166/232] Processando 30 itens...\n",
            "[Batch 167/232] Processando 30 itens...\n",
            "[Batch 168/232] Processando 30 itens...\n",
            "[Batch 169/232] Processando 30 itens...\n",
            "[Batch 170/232] Processando 30 itens...\n",
            "[Batch 171/232] Processando 30 itens...\n",
            "[Batch 172/232] Processando 30 itens...\n",
            "[Batch 173/232] Processando 30 itens...\n",
            "[Batch 174/232] Processando 30 itens...\n",
            "[Batch 175/232] Processando 30 itens...\n",
            "[Batch 176/232] Processando 30 itens...\n",
            "[Batch 177/232] Processando 30 itens...\n",
            "[Batch 178/232] Processando 30 itens...\n",
            "[Batch 179/232] Processando 30 itens...\n",
            "[Batch 180/232] Processando 30 itens...\n",
            "[Batch 181/232] Processando 30 itens...\n",
            "[Batch 182/232] Processando 30 itens...\n",
            "[Batch 183/232] Processando 30 itens...\n",
            "[Batch 184/232] Processando 30 itens...\n",
            "[Batch 185/232] Processando 30 itens...\n",
            "[Batch 186/232] Processando 30 itens...\n",
            "[Batch 187/232] Processando 30 itens...\n",
            "[Batch 188/232] Processando 30 itens...\n",
            "[Batch 189/232] Processando 30 itens...\n",
            "[Batch 190/232] Processando 30 itens...\n",
            "[Batch 191/232] Processando 30 itens...\n",
            "[Batch 192/232] Processando 30 itens...\n",
            "[Batch 193/232] Processando 30 itens...\n",
            "[Batch 194/232] Processando 30 itens...\n",
            "[Batch 195/232] Processando 30 itens...\n",
            "[Batch 196/232] Processando 30 itens...\n",
            "[Batch 197/232] Processando 30 itens...\n",
            "[Batch 198/232] Processando 30 itens...\n",
            "[Batch 199/232] Processando 30 itens...\n",
            "[Batch 200/232] Processando 30 itens...\n",
            "[Batch 201/232] Processando 30 itens...\n",
            "[Batch 202/232] Processando 30 itens...\n",
            "[Batch 203/232] Processando 30 itens...\n",
            "[Batch 204/232] Processando 30 itens...\n",
            "[Batch 205/232] Processando 30 itens...\n",
            "[Batch 206/232] Processando 30 itens...\n",
            "[Batch 207/232] Processando 30 itens...\n",
            "[Batch 208/232] Processando 30 itens...\n",
            "[Batch 209/232] Processando 30 itens...\n",
            "[Batch 210/232] Processando 30 itens...\n",
            "[Batch 211/232] Processando 30 itens...\n",
            "[Batch 212/232] Processando 30 itens...\n",
            "[Batch 213/232] Processando 30 itens...\n",
            "[Batch 214/232] Processando 30 itens...\n",
            "[Batch 215/232] Processando 30 itens...\n",
            "[Batch 216/232] Processando 30 itens...\n",
            "[Batch 217/232] Processando 30 itens...\n",
            "[Batch 218/232] Processando 30 itens...\n",
            "[Batch 219/232] Processando 30 itens...\n",
            "[Batch 220/232] Processando 30 itens...\n",
            "[Batch 221/232] Processando 30 itens...\n",
            "[Batch 222/232] Processando 30 itens...\n",
            "[Batch 223/232] Processando 30 itens...\n",
            "[Batch 224/232] Processando 30 itens...\n",
            "[Batch 225/232] Processando 30 itens...\n",
            "[Batch 226/232] Processando 30 itens...\n",
            "[Batch 227/232] Processando 30 itens...\n",
            "[Batch 228/232] Processando 30 itens...\n",
            "[Batch 229/232] Processando 30 itens...\n",
            "[Batch 230/232] Processando 30 itens...\n",
            "[Batch 231/232] Processando 30 itens...\n",
            "[Batch 232/232] Processando 26 itens...\n",
            "\n",
            "================ RELATÓRIO ================\n",
            "\n",
            "Arquivo de saída: /content/drive/MyDrive/0_tupi/tupiantigo_portugues_modernizado.csv\n",
            "Linhas totais: 6956\n",
            "\n",
            "Exemplos 'iguais' (até 15): 15\n",
            "- ID 1: doravante assim procedo\n",
            "- ID 3: é discreta, falando aos homens\n",
            "- ID 4: para se vingar de seu cão que cria, um homem não o alimenta\n",
            "- ID 5: dizem que foi\n",
            "- ID 6: vem para espantar o diabo, para que não me dane\n",
            "- ID 7: como a esses, matarei os que costumam pecar, fazendo-os cair comigo em meu fogo\n",
            "- ID 8: vou como catador de madeira\n",
            "- ID 9: examinando a armadilha de alguém, tomando o seu conteúdo\n",
            "- ID 11: mostra o erro de minhas palavras\n",
            "- ID 13: eu tenho cabelos muito arrepiados\n",
            "- ID 14: fora, na rua\n",
            "- ID 16: podem deixar um do outro?\n",
            "- ID 17: eu retomei o bom senso\n",
            "- ID 18: eis que era costume, então, dar nome às pessoas\n",
            "- ID 19: vou com ele\n",
            "\n",
            "Exemplos 'muito alteradas' (similaridade < 0.8, até 15): 15\n",
            "\n",
            "- ID 15 | similaridade=0.706\n",
            "  Original:    matai-o!\n",
            "  Modernizado: matem-no!\n",
            "\n",
            "- ID 35 | similaridade=0.750\n",
            "  Original:    saiu-me de través\n",
            "  Modernizado: saiu-me de lado\n",
            "\n",
            "- ID 46 | similaridade=0.786\n",
            "  Original:    não vos perceberam abaixai-vos\n",
            "  Modernizado: não perceberam, abaixem-se\n",
            "\n",
            "- ID 60 | similaridade=0.792\n",
            "  Original:    violentaste uma solteira antes de lhe fazer mal?\n",
            "  Modernizado: Você violentou uma solteira antes de fazer mal a ela?\n",
            "\n",
            "- ID 62 | similaridade=0.600\n",
            "  Original:    ah, vencer-me-ão hoje!\n",
            "  Modernizado: Ah, eles vão me vencer hoje!\n",
            "\n",
            "- ID 66 | similaridade=0.598\n",
            "  Original:    tão logo ao ouvir o nome dela, em outra parte eu me escondo\n",
            "  Modernizado: Assim que ouvir o nome dela, eu me escondo em outra parte.\n",
            "\n",
            "- ID 67 | similaridade=0.485\n",
            "  Original:    morrendo nós\n",
            "  Modernizado: Nós estamos morrendo.\n",
            "\n",
            "- ID 70 | similaridade=0.636\n",
            "  Original:    escorei-o\n",
            "  Modernizado: Eu o escorei.\n",
            "\n",
            "- ID 73 | similaridade=0.643\n",
            "  Original:    livra-nos tu\n",
            "  Modernizado: Livra-nos, você.\n",
            "\n",
            "- ID 76 | similaridade=0.766\n",
            "  Original:    meteu-te pelo pescoço\n",
            "  Modernizado: Ele te meteu pelo pescoço.\n",
            "\n",
            "- ID 91 | similaridade=0.686\n",
            "  Original:    enfileiramo-nos\n",
            "  Modernizado: nós nos enfileiramos\n",
            "\n",
            "- ID 92 | similaridade=0.718\n",
            "  Original:    ofendeste tua avó?\n",
            "  Modernizado: você ofendeu sua avó?\n",
            "\n",
            "- ID 93 | similaridade=0.737\n",
            "  Original:    eu sumi de vista\n",
            "  Modernizado: eu desapareci de vista\n",
            "\n",
            "- ID 99 | similaridade=0.769\n",
            "  Original:    cortei-lhe a cabeça\n",
            "  Modernizado: cortei a cabeça dele\n",
            "\n",
            "- ID 105 | similaridade=0.632\n",
            "  Original:    eia, pois, vamos estar sentados aqui\n",
            "  Modernizado: vamos nos sentar aqui\n",
            "\n",
            "Processo concluído.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Amostra com o prompt atual"
      ],
      "metadata": {
        "id": "I6GmP7qVYH0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para rodar o teste rápido:\n",
        "processar_csv_amostra(sample_size=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_3gzSiT5Vks",
        "outputId": "44a25900-b272-40a2-9d89-569c76d23c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Info] Coluna 'id' não existia; criei IDs sequenciais.\n",
            "\n",
            "===== AMOSTRA =====\n",
            "\n",
            "ID 0\n",
            "Original:    aparei as pontas deles\n",
            "Modernizado: aparar as pontas deles\n",
            "Status: similaridade=0.909\n",
            "\n",
            "ID 10\n",
            "Original:    tu te comprazes quando um homem apalpa teus seios?\n",
            "Modernizado: você se compraz quando um homem apalpa seus seios?\n",
            "Status: similaridade=0.880\n",
            "\n",
            "ID 12\n",
            "Original:    afastaste teu filho e teu escravo de suas amantes?\n",
            "Modernizado: afastou seu filho e seu escravo de suas amantes?\n",
            "Status: similaridade=0.898\n",
            "\n",
            "ID 15\n",
            "Original:    matai-o!\n",
            "Modernizado: matem-no!\n",
            "Status: similaridade=0.706\n",
            "\n",
            "ID 22\n",
            "Original:    estando doente, de verdade, não a ouviste, ou sendo preguiçoso?\n",
            "Modernizado: estando doente, de verdade, não a ouviu, ou sendo preguiçoso?\n",
            "Status: similaridade=0.968\n",
            "\n",
            "ID 25\n",
            "Original:    que se alegre esta vossa terra\n",
            "Modernizado: que se alegre esta sua terra\n",
            "Status: similaridade=0.931\n",
            "\n",
            "ID 26\n",
            "Original:    confesso-me a ti, senhor padre, por causa do meu pecar muitas vezes\n",
            "Modernizado: confesso-me a você, senhor padre, por causa do meu pecar muitas vezes\n",
            "Status: similaridade=0.956\n",
            "\n",
            "ID 27\n",
            "Original:    amo pedro, assim como a seu filho\n",
            "Modernizado: amo Pedro, assim como a seu filho\n",
            "Status: similaridade=0.970\n",
            "\n",
            "ID 29\n",
            "Original:    foste para revistar as cisternas de água doce de alguém, tomando seu conteúdo?\n",
            "Modernizado: você foi para revistar as cisternas de água doce de alguém, tomando seu conteúdo?\n",
            "Status: similaridade=0.943\n",
            "\n",
            "ID 32\n",
            "Original:    vinde todos para festejar a jesus\n",
            "Modernizado: venham todos para festejar a Jesus\n",
            "Status: similaridade=0.866\n",
            "\n",
            "ID 33\n",
            "Original:    como estas são vossas casas? -diferem muito\n",
            "Modernizado: como estas são suas casas? -diferem muito\n",
            "Status: similaridade=0.952\n",
            "\n",
            "ID 34\n",
            "Original:    nosso criador fazes estar contigo em teus braços\n",
            "Modernizado: nosso criador faz você estar contigo em seus braços\n",
            "Status: similaridade=0.909\n",
            "\n",
            "ID 41\n",
            "Original:    as crianças habitantes da aldeia de belém e também as habitantes das suas vizinhanças mandou assassinar, nelas querendo incluir nosso senhor\n",
            "Modernizado: as crianças habitantes da aldeia de Belém e também as habitantes das suas vizinhanças mandou assassinar, nelas querendo incluir nosso Senhor\n",
            "Status: similaridade=0.986\n",
            "\n",
            "ID 44\n",
            "Original:    se tu não endureceres teu coração\n",
            "Modernizado: se você não endurecer seu coração\n",
            "Status: similaridade=0.848\n",
            "\n",
            "ID 46\n",
            "Original:    não vos perceberam abaixai-vos\n",
            "Modernizado: não perceberam, abaixem-se\n",
            "Status: similaridade=0.786\n",
            "\n",
            "ID 50\n",
            "Original:    por isso mesmo em tua grande força apóio-me\n",
            "Modernizado: por isso mesmo em sua grande força me apoio\n",
            "Status: similaridade=0.884\n",
            "\n",
            "ID 55\n",
            "Original:    mas procedendo de que modo se está como amigo do diabo?\n",
            "Modernizado: mas, de verdade\n",
            "Status: similaridade=0.286\n",
            "\n",
            "ID 58\n",
            "Original:    apenas não me faz morrer\n",
            "Modernizado: apenas não me faça morrer\n",
            "Status: similaridade=0.939\n",
            "\n",
            "ID 60\n",
            "Original:    violentaste uma solteira antes de lhe fazer mal?\n",
            "Modernizado: violentou uma solteira antes de lhe fazer mal?\n",
            "Status: similaridade=0.936\n",
            "\n",
            "ID 71\n",
            "Original:    os que moram em maratauá acreditam em minhas palavras\n",
            "Modernizado: os que moram em Maratauá acreditam em minhas palavras\n",
            "Status: similaridade=0.981\n",
            "\n",
            "ID 73\n",
            "Original:    livra-nos tu\n",
            "Modernizado: livra-nos você\n",
            "Status: similaridade=0.769\n",
            "\n",
            "ID 75\n",
            "Original:    conhecendo a deus\n",
            "Modernizado: conhecendo a Deus\n",
            "Status: similaridade=0.941\n",
            "\n",
            "ID 76\n",
            "Original:    meteu-te pelo pescoço\n",
            "Modernizado: meteu-se pelo pescoço\n",
            "Status: similaridade=0.952\n",
            "\n",
            "ID 78\n",
            "Original:    embora eles fossem obra d'ele, alguns anjos tornaram-se maus\n",
            "Modernizado: embora eles fossem obra dele, alguns anjos tornaram-se maus\n",
            "Status: similaridade=0.992\n",
            "\n",
            "ID 85\n",
            "Original:    tomaste remédio, não querendo ficar grávida?\n",
            "Modernizado: tomou remédio, não querendo ficar grávida?\n",
            "Status: similaridade=0.930\n",
            "\n",
            "ID 90\n",
            "Original:    acreditaste nas mentiras de alguém?\n",
            "Modernizado: acreditou nas mentiras de alguém?\n",
            "Status: similaridade=0.912\n",
            "\n",
            "ID 92\n",
            "Original:    ofendeste tua avó?\n",
            "Modernizado: ofendeu sua avó?\n",
            "Status: similaridade=0.824\n",
            "\n",
            "ID 96\n",
            "Original:    vituperaste teu pai, tua mãe, teu avô, tua avó?\n",
            "Modernizado: vituperou seu pai, sua mãe, seu avô, sua avó?\n",
            "Status: similaridade=0.848\n",
            "\n"
          ]
        }
      ]
    }
  ]
}